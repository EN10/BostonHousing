{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Regression from Scratch Example](https://www.kaggle.com/code/aakashns/pytorch-basics-linear-regression-from-scratch)"
      ],
      "metadata": {
        "id": "HyExCmX_0xhn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yjZMH2tbz_Z8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1938b22-d818-4a09-94e3-3c0a8d7657f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing Data\n",
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(boston.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Input RM rooms attribute\n",
        "inputs = torch.tensor(boston.data[:,5])\n",
        "# Target is price\n",
        "targets = torch.tensor(boston.target)"
      ],
      "metadata": {
        "id": "HTsE0xlm40l5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases price = w * (rooms) + b\n",
        "w = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Define the model\n",
        "def model(x):\n",
        "    return x @ w.t() + b"
      ],
      "metadata": {
        "id": "u8pLVeWA1Auo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean square error\n",
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "MQNaeohALQ2Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 10 epochs\n",
        "for i in range(10):\n",
        "  for j in range(506):\n",
        "      rooms = torch.Tensor([inputs[j]])\n",
        "      preds = model(rooms)\n",
        "      loss = mse(preds, targets)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "          w -= w.grad * 1e-5\n",
        "          b -= b.grad * 1e-5\n",
        "          w.grad.zero_()\n",
        "          b.grad.zero_()\n",
        "  print('loss:' , loss.item())  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp8eucPMLSp9",
        "outputId": "58387eda-7c91-49d4-99e4-465d746f3643"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 168.70078542972817\n",
            "loss: 125.80690435055655\n",
            "loss: 105.75413023609012\n",
            "loss: 96.12032708991441\n",
            "loss: 91.3323385860215\n",
            "loss: 88.85681234511114\n",
            "loss: 87.52143491703195\n",
            "loss: 86.77010984435192\n",
            "loss: 86.3308244456969\n",
            "loss: 86.06546142138275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "rooms = 6.0\n",
        "input = torch.tensor([rooms])\n",
        "price = model(input).item()\n",
        "print('price:' , price)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQufYtBaMSqS",
        "outputId": "7c9265d3-dd3c-4982-aa41-f293c44b0d23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: 21.151033401489258\n"
          ]
        }
      ]
    }
  ]
}