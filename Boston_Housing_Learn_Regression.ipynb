{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Regression from Scratch Example](https://www.kaggle.com/code/aakashns/pytorch-basics-linear-regression-from-scratch)"
      ],
      "metadata": {
        "id": "HyExCmX_0xhn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjZMH2tbz_Z8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594e5fd1-2863-415f-fda2-e2cb81ba8a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing Data\n",
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(boston.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# input RM rooms attribute\n",
        "inputs = torch.tensor(boston.data[:,5])\n",
        "# target is price\n",
        "targets = torch.tensor(boston.target)"
      ],
      "metadata": {
        "id": "HTsE0xlm40l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases price = w * (rooms) + b\n",
        "w = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Define the model\n",
        "def model(x):\n",
        "    return x @ w.t() + b"
      ],
      "metadata": {
        "id": "u8pLVeWA1Auo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean square error\n",
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "MQNaeohALQ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 10 epochs\n",
        "for i in range(10):\n",
        "  for j in range(506):\n",
        "      rooms = torch.Tensor([inputs[j]])\n",
        "      preds = model(rooms)\n",
        "      loss = mse(preds, targets)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "          w -= w.grad * 1e-5\n",
        "          b -= b.grad * 1e-5\n",
        "          w.grad.zero_()\n",
        "          b.grad.zero_()\n",
        "  print(loss)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp8eucPMLSp9",
        "outputId": "65db10a5-951c-4c98-94ad-549b59c5d517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(343.7089, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(205.7284, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(142.9948, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(113.9475, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(100.1656, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(93.4195, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(89.9919, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(88.1763, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(87.1727, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(86.5951, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "rooms = torch.tensor([6.0])\n",
        "model(rooms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQufYtBaMSqS",
        "outputId": "e03806a5-4acf-4d40-8474-ec1c1ac0d2fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([20.9574], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}